{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ebb6cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import color, io\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4bb2af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 36000 files into human database\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HUMANS IMAGES\n",
    "#########################\n",
    "\n",
    "humans_path = '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/synthetic_images'\n",
    "\n",
    "all_humans = []\n",
    "\n",
    "for root, dirs, files in sorted(os.walk(humans_path)):\n",
    "\n",
    "    for name in files:\n",
    "        if not name.startswith(\".\"):\n",
    "            all_humans.append(str(root) + \"/\" + str(name))\n",
    "\n",
    "all_humans = sorted(all_humans)\n",
    "\n",
    "print(\"loaded %d files into human database\" % len(all_humans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4159a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3000 files into female_humans_annotations database\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/annotations/female/subject_mesh_0001_anno.json\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/annotations/female/subject_mesh_1235_anno.json\n",
      "loaded 3000 files into male_humans_annotations database\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/annotations/male/subject_mesh_0001_anno.json\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/annotations/male/subject_mesh_3000_anno.json\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HUMANS ANNOTATIONS\n",
    "#########################\n",
    "\n",
    "humans_annotations_path = '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/annotations'\n",
    "\n",
    "female_humans_annotations = []\n",
    "male_humans_annotations = []\n",
    "\n",
    "for root, dirs, files in sorted(os.walk(humans_annotations_path)):\n",
    "    for name in files:\n",
    "        if not name.startswith(\".\"):\n",
    "            if \"female\" in root:\n",
    "                female_humans_annotations.append(str(root) + \"/\" + str(name))\n",
    "            else:\n",
    "                male_humans_annotations.append(str(root) + \"/\" + str(name))\n",
    "\n",
    "female_humans_annotations = sorted(female_humans_annotations)\n",
    "male_humans_annotations = sorted(male_humans_annotations)\n",
    "\n",
    "print(\"loaded %d files into female_humans_annotations database\" % len(female_humans_annotations))\n",
    "print(female_humans_annotations[0])\n",
    "print(female_humans_annotations[1234])\n",
    "print(\"loaded %d files into male_humans_annotations database\" % len(male_humans_annotations))\n",
    "print(male_humans_annotations[0])\n",
    "print(male_humans_annotations[2999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9da1435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded:\n",
      "----------------------------------------------------\n",
      "Examples:\n",
      "----------------------------------------------------\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/synthetic_images/200x200/pose0/female/subject_mesh_0001-m-jeans.png\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/synthetic_images/200x200/pose0/female/subject_mesh_0001-m.png\n",
      "/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/synthetic_images/200x200/pose0/female/subject_mesh_0001-m-ein.png\n",
      "----------------------------------------------------\n",
      "Numbers:\n",
      "----------------------------------------------------\n",
      "12000\n",
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# DATA SORTING\n",
    "##############################################################\n",
    "\n",
    "##############################\n",
    "# HUMANS\n",
    "##############################\n",
    "\n",
    "humans_plain_paths = []\n",
    "humans_one_paths = []\n",
    "humans_jeans_paths = []\n",
    "\n",
    "for human in all_humans:\n",
    "    if \"ein\" in human:\n",
    "        humans_one_paths.append(human)\n",
    "    elif \"jeans\" in human:\n",
    "        humans_jeans_paths.append(human)\n",
    "    else:\n",
    "        humans_plain_paths.append(human)\n",
    "\n",
    "##############################\n",
    "# OUTPUT\n",
    "##############################\n",
    "print(\"Images loaded:\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Examples:\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(humans_jeans_paths[0])\n",
    "print(humans_plain_paths[0])\n",
    "print(humans_one_paths[0])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Numbers:\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(len(humans_jeans_paths))\n",
    "print(len(humans_plain_paths))\n",
    "print(len(humans_one_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae6b9b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "import re\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "# create 3 random arrays for 3 datasets to train/test the cnn\n",
    "numbers_plain = rng.choice(12000, size=10000, replace=False)\n",
    "numbers_jeans = rng.choice(12000, size=10000, replace=False)\n",
    "numbers_one = rng.choice(12000, size=10000, replace=False)\n",
    "\n",
    "##############################################################\n",
    "# CONVERT IMAGES TO GRAYSCALE\n",
    "##############################################################\n",
    "\n",
    "# def get_female_ann(file):\n",
    "#     id = get_id(file)-1\n",
    "#     file = file[file.rfind('/')+1:]\n",
    "#     # female_human_annotation = json.load(file)\n",
    "#     with open(female_humans_annotations[id], 'r') as file:\n",
    "#             # load from json\n",
    "#             female_human_annotation = json.load(file)\n",
    "#             sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "#             sub_df = sub_df.transpose()\n",
    "#     return file\n",
    "\n",
    "def get_male_ann(file):\n",
    "    file = file[file.rfind('/')+1:]\n",
    "    return file\n",
    "\n",
    "def get_gender(filename):\n",
    "    return filename[-5:-4]\n",
    "\n",
    "def get_id(filename):\n",
    "    return remove_non_int(filename[-17:])\n",
    "\n",
    "def remove_non_int(str):\n",
    "    return int(re.sub(\"[^0-9]\", \"\", str))\n",
    "\n",
    "# for file_path in humans_plain_paths:\n",
    "#     print(file_path)\n",
    "#     print(get_female_ann(file_path))\n",
    "#     print(get_gender(file_path))\n",
    "#     print(get_id(file_path))\n",
    "\n",
    "\n",
    "# for female_humans_annotation_path in female_humans_annotations:\n",
    "#     if not \"DS_Store\" in female_humans_annotation_path:\n",
    "#         with open(female_humans_annotation_path, 'r') as file:\n",
    "#             # load from json\n",
    "#             female_human_annotation = json.load(file)\n",
    "#             sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "#             sub_df = sub_df.transpose()\n",
    "#\n",
    "#             #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "#             humans_annotations_df = pd.concat([humans_annotations_df, sub_df])\n",
    "\n",
    "\n",
    "\n",
    "# reduce number of images for testing purposes\n",
    "n_images = 1000000\n",
    "\n",
    "humans_plain_train, humans_plain_test = [], []\n",
    "humans_plain_train_ann_df, humans_plain_test_ann_df = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "humans_jeans_grey_train, humans_jeans_grey_test = [], []\n",
    "humans_jeans_grey_train_ann_df, humans_jeans_grey_test_ann_df = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "humans_one_grey_train, humans_one_grey_test = [], []\n",
    "humans_one_grey_train_ann_df, humans_one_grey_test_ann_df = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "##############################\n",
    "# HUMANS PLAIN\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_plain_paths:\n",
    "    human_plain = io.imread(file_path)\n",
    "    id = get_id(file_path)-1\n",
    "    gender = get_gender(file_path)\n",
    "\n",
    "    if i in numbers_plain:\n",
    "        humans_plain_train.append(human_plain)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                # print(human_annotation)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_plain_train_ann_df = pd.concat([humans_plain_train_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                # print(human_annotation)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "                # print(sub_df)\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_plain_train_ann_df = pd.concat([humans_plain_train_ann_df, sub_df])\n",
    "\n",
    "    else:\n",
    "        humans_plain_test.append(human_plain)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_plain_test_ann_df = pd.concat([humans_plain_test_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_plain_test_ann_df = pd.concat([humans_plain_test_ann_df, sub_df])\n",
    "    if i == n_images:\n",
    "        break\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"1\")\n",
    "##############################\n",
    "# HUMANS W TEXTURE FOREGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_jeans_paths:\n",
    "    human_texture_grey = color.rgb2gray(io.imread(file_path))\n",
    "    id = get_id(file_path)-1\n",
    "    gender = get_gender(file_path)\n",
    "\n",
    "    if i in numbers_jeans:\n",
    "        humans_jeans_grey_train.append(human_texture_grey)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_jeans_grey_train_ann_df = pd.concat([humans_jeans_grey_train_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_jeans_grey_train_ann_df = pd.concat([humans_jeans_grey_train_ann_df, sub_df])\n",
    "    else:\n",
    "        humans_jeans_grey_test.append(human_texture_grey)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_jeans_grey_test_ann_df = pd.concat([humans_jeans_grey_test_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_jeans_grey_test_ann_df = pd.concat([humans_jeans_grey_test_ann_df, sub_df])\n",
    "\n",
    "    if i == n_images:\n",
    "        break\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"2\")\n",
    "##############################\n",
    "# HUMANS W SOLID FOREGROUND\n",
    "##############################\n",
    "\n",
    "i = 0\n",
    "\n",
    "for file_path in humans_one_paths:\n",
    "    human_rgb_grey = color.rgb2gray(io.imread(file_path))\n",
    "    id = get_id(file_path)-1\n",
    "    gender = get_gender(file_path)\n",
    "\n",
    "    if i in numbers_one:\n",
    "        humans_one_grey_train.append(human_rgb_grey)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_one_grey_train_ann_df = pd.concat([humans_one_grey_train_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_one_grey_train_ann_df = pd.concat([humans_one_grey_train_ann_df, sub_df])\n",
    "    else:\n",
    "        humans_one_grey_test.append(human_rgb_grey)\n",
    "        if gender == \"f\":\n",
    "            with open(female_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_one_grey_test_ann_df = pd.concat([humans_one_grey_test_ann_df, sub_df])\n",
    "        else:\n",
    "            with open(male_humans_annotations[id], 'r') as file:\n",
    "                # load from json\n",
    "                human_annotation = json.load(file)\n",
    "                sub_df = pd.DataFrame.from_dict(human_annotation['human_dimensions'], orient='index')\n",
    "                sub_df = sub_df.transpose()\n",
    "\n",
    "                #humans_annotations_df = humans_annotations_df.append(sub_df, ignore_index=True)\n",
    "                humans_one_grey_test_ann_df = pd.concat([humans_one_grey_test_ann_df, sub_df])\n",
    "\n",
    "    if i == n_images:\n",
    "        break\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chest_circumference', 'height', 'inseam', 'left_arm_length',\n",
      "       'pelvis_circumference', 'right_arm_length', 'shoulder_width',\n",
      "       'waist_circumference'],\n",
      "      dtype='object')\n",
      "   chest_circumference    height    inseam  left_arm_length  \\\n",
      "0             1.199463  1.934066  0.836919         0.651372   \n",
      "0             1.022033  1.574711  0.593292         0.502548   \n",
      "0             1.103838  1.907959  0.821567         0.619892   \n",
      "0             1.361146  2.009109  0.850917         0.672863   \n",
      "0             1.003971  1.542366  0.692716         0.505650   \n",
      "\n",
      "   pelvis_circumference  right_arm_length  shoulder_width  waist_circumference  \n",
      "0              1.167261          0.664282        0.456476             1.063651  \n",
      "0              0.962600          0.521710        0.428650             0.856717  \n",
      "0              1.069130          0.643452        0.442495             0.964508  \n",
      "0              1.237328          0.678925        0.475370             1.240309  \n",
      "0              0.944154          0.511876        0.403204             0.871987  \n"
     ]
    }
   ],
   "source": [
    "print(humans_one_grey_train_ann_df.columns)\n",
    "print(humans_one_grey_train_ann_df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans_one dataset: 10000, 2000\n",
      "humans_plain dataset: 10000, 2000\n",
      "humans_jeans dataset: 10000, 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"humans_one dataset: \" + str(len(humans_one_grey_train)) + \", \" + str(len(humans_one_grey_test)))\n",
    "print(\"humans_plain dataset: \" + str(len(humans_plain_train)) + \", \" + str(len(humans_plain_test)))\n",
    "print(\"humans_jeans dataset: \" + str(len(humans_jeans_grey_train)) + \", \" + str(len(humans_jeans_grey_test)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e7d6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rl/xp7lnvk10sx90l166vcpd6p80000gn/T/ipykernel_26771/2711629265.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  humans_plain_image_train_tensor = torch.tensor(humans_plain_train)\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# CREATE DATA FRAME OF IMAGE VECTORS AND ANNOTATIONS\n",
    "##############################################################\n",
    "\n",
    "##############################\n",
    "# HUMAN PLAIN DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_plain_image_train_tensor = torch.tensor(humans_plain_train)\n",
    "humans_plain_image_test_tensor = torch.tensor(humans_plain_test)\n",
    "humans_plain_ann_train_tensor = torch.tensor(humans_plain_train_ann_df.values)\n",
    "humans_plain_ann_test_tensor = torch.tensor(humans_plain_test_ann_df.values)\n",
    "\n",
    "##############################\n",
    "# HUMAN RGB DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_one_image_train_tensor = torch.tensor(humans_one_grey_train)\n",
    "humans_one_image_test_tensor = torch.tensor(humans_one_grey_test)\n",
    "humans_one_ann_train_tensor = torch.tensor(humans_one_grey_train_ann_df.values)\n",
    "humans_one_ann_test_tensor = torch.tensor(humans_one_grey_test_ann_df.values)\n",
    "\n",
    "##############################\n",
    "# HUMAN TEXTURE DATA FRAME\n",
    "##############################\n",
    "\n",
    "# tensor of images w.o. annotations\n",
    "humans_jeans_image_train_tensor = torch.tensor(humans_jeans_grey_train)\n",
    "humans_jeans_image_test_tensor = torch.tensor(humans_jeans_grey_test)\n",
    "humans_jeans_ann_train_tensor = torch.tensor(humans_jeans_grey_train_ann_df.values)\n",
    "humans_jeans_ann_test_tensor = torch.tensor(humans_jeans_grey_test_ann_df.values)\n",
    "\n",
    "############################################################\n",
    "# STORE TENSORS IN FILE\n",
    "############################################################\n",
    "\n",
    "##############################\n",
    "# PLAIN\n",
    "##############################\n",
    "\n",
    "torch.save(humans_plain_image_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_plain_image_train_tensor.pt')\n",
    "torch.save(humans_plain_image_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_plain_image_test_tensor.pt')\n",
    "torch.save(humans_plain_ann_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_plain_ann_train_tensor.pt')\n",
    "torch.save(humans_plain_ann_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_plain_ann_test_tensor.pt')\n",
    "\n",
    "##############################\n",
    "# ONE COLOR\n",
    "##############################\n",
    "\n",
    "torch.save(humans_one_image_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_one_image_train_tensor.pt')\n",
    "torch.save(humans_one_image_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_one_image_test_tensor.pt')\n",
    "torch.save(humans_one_ann_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_one_ann_train_tensor.pt')\n",
    "torch.save(humans_one_ann_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_one_ann_test_tensor.pt')\n",
    "\n",
    "##############################\n",
    "# JEANS\n",
    "##############################\n",
    "\n",
    "torch.save(humans_jeans_image_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_jeans_image_train_tensor.pt')\n",
    "torch.save(humans_jeans_image_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_jeans_image_test_tensor.pt')\n",
    "torch.save(humans_jeans_ann_train_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_jeans_ann_train_tensor.pt')\n",
    "torch.save(humans_jeans_ann_test_tensor, '/Users/daniilbarkov/MyProjects/Uni/Pattern2/dataset/tensors/humans_jeans_ann_test_tensor.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
